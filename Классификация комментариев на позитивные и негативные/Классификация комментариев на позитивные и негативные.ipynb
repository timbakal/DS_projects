{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала импортируем всевозможные необходимые пакеты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import lightgbm as lgb\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import f1_score\n",
    "import transformers\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь импортируем файл с данными и проанализируем ео на наличие ошибок и аутлаеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159292.000000\n",
       "mean        0.101612\n",
       "std         0.302139\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никаких странных значений нету, аутлаеров тоже не выявлено, данные понятный, ровные, ничего выбивающегося. А значит время делать сэмплирование\n",
    "\n",
    "Единсвтенное замечание - это что у таргета очень мало негативный комментариев, всего 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "Молодец, исследован баланс классов. Это важная информация для задачи классификации.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также стоит сделать лемматизацию и очистку текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(text)):\n",
    "    r = re.sub('[^a-zA-Z]', ' ', text[i])\n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    r = ' '.join(r)\n",
    "    r = r.lower()\n",
    "    corpus.append(r)\n",
    "    \n",
    "data['text'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 51s, sys: 1.69 s, total: 13min 53s\n",
      "Wall time: 13min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join([y.lemma_ for y in nlp(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>second time ask view completely contradict cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm there s actual article prostitutio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>really think understand come idea bad right aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation edit make username hardcore metall...      0\n",
       "1       aww match background colour seemingly stick th...      0\n",
       "2       hey man really try edit war guy constantly rem...      0\n",
       "3       make real suggestion improvement wonder sectio...      0\n",
       "4                           sir hero chance remember page      0\n",
       "...                                                   ...    ...\n",
       "159446  second time ask view completely contradict cov...      0\n",
       "159447               ashamed horrible thing put talk page      0\n",
       "159448  spitzer umm there s actual article prostitutio...      0\n",
       "159449  look like actually put speedy first version de...      0\n",
       "159450  really think understand come idea bad right aw...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитал про спейси, так действительно легче "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    " 👍 \n",
    "\n",
    "Текст очищен, но я советую при чистке оставить символ ' (апостроф), он играет важную роль в английском языке.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Твой код можно сделать оптимальнее. \n",
    "    \n",
    " 1. Отказывайся от конструкций  типа \n",
    "    \n",
    "        for i in range(len(corpus)):\n",
    "    \n",
    "    Гораздо по питоновски выглядит вот такой код:\n",
    "        for sentence in corpus:\n",
    "    \n",
    "    Еще короче,  откзазываемся от \"переделки\" pd.Series в list и просто проитерируемся по pd.Series\n",
    "    \n",
    "        for sentence in data['text']:\n",
    "    \n",
    " 2. Но и это не самое короткое и оптимальное.  Вот такой вариант выглядит лучше и поднятнее:\n",
    "\n",
    "    \n",
    "         data['lemm_text'] = data['text'].apply(clear_text)\n",
    "         data['lemm_text'] = data['lemm_text'].apply(lemmafunction)\n",
    "\n",
    "    \n",
    "Если операция выполняется долго, лучше добавить прогресс-бар.  Тогда используем progress_apply\n",
    "    \n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "\n",
    "    data['lemm_text'] = data['text'].progress_apply(clear_text)\n",
    "    data['lemm_text'] = data['lemm_text'].progress_apply(lemmafunction)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "\n",
    "Я сначала сделал точь в точь как вы и написать во 2 пункте, 1 в 1 было,  но из за того что оно очень долго выполнлось, я решил попробовать так, так оно выполнилось гораздо быстрее\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\"> \n",
    " <b>v2</b>\n",
    "Молодец, что используешь spacy, а также отлключил лишние операции. Это заметно ускоряет процесс лемматизации.\n",
    "\n",
    "    \n",
    "    \n",
    "Кстати, есть еще один способ ускорить лемматизацию. \n",
    "    \n",
    "Можно использовать spaCy pipeline (https://spacy.io/usage/processing-pipelines)\n",
    "    \n",
    "    \n",
    "    lemm_texts = []\n",
    "    total = data.shape[0]\n",
    "    nlp_pipe = nlp.pipe(data['text'].values, disable = ['ner', 'parser'])\n",
    "    \n",
    "    for doc in tqdm(nlp_pipe, total=total):\n",
    "        lemm_text = \" \".join([token.lemma_ for token in doc])    \n",
    "        lemm_texts.append(lemm_text) \n",
    "    \n",
    "Когда я проверял, у меня получилось ускорить почти в два раза.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "Молодец, что используешь лемматизатор WordNetLemmatizer. Но в данном случае он отработал не очень хорошо, и если присмотреться к тексту это хорошо видно. Например, в в нулевой строке есть глагол made, а его начальная форма make. \n",
    "    \n",
    "Как правило, совершаются следующие ошибки:\n",
    "    \n",
    " - Лемматизация должна производиться по одному слову, а не весь комментарий целиком\n",
    " - Слова должны быть приведены к нижнему регистру\n",
    " - Кроме самого слова в лемматизатор нужно передать дополнительную информацию о части речи слова (POS тег). \n",
    "    \n",
    "    \n",
    "    \n",
    "Ты можешь доработать подход с WordNetLemmatizer или использовать spaCy, там все отрабатывает \"из коробки\". Можешь посмотреть вот эту статью.  \n",
    "\n",
    "\n",
    "https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "    \n",
    "Хочу обратить твое внимание, что код из вышеуказанной статьи выполняется несколько дольше, чем оптимизированный, вот из этого топика\n",
    "    \n",
    "https://stackoverflow.com/questions/50992974/nltk-wordnetlemmatizer-not-lemmatizing-as-expected    \n",
    "    \n",
    "    \n",
    "    \n",
    "Совет - старайся сразу проверять  результаты лемматизации. Например, для предложения\n",
    "    \n",
    "    sentence = \"The striped bats are hanging on their feet for best\"\n",
    "    \n",
    "После лемматизации должен получиться вот такой результат\n",
    "    \n",
    "    \"the strip bat be hang on their foot for best\"    \n",
    "    \n",
    "Если будешь лемматизировать по второму способу, то слово  striped может остаться без изменений, это тоже  нормально (особенность алгоритма).       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наши данные готовы к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text']\n",
    "target = data['toxic']\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Данные разделены на выборки. Но я бы посоветовал тебе изменить пропорции и выделить на тест 10%. Причина простая - модели, которые мы обучаем чувствительны к объему обучающих данных. Чем больше слов они увидят в процессе обучения, и оценят их вклад в \"токсичность\", тем лучше будут модели. А для корректного тестирования и 10% данных вполне достаточно, учитывая немаленький размер датасета.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "Старайся не делать такие длинные строки. Стандарт PEP8 регулирует длину строки 79 символов. Придерживаться такого очень сложно, но лучше хотя-бы вмещать в экран, чтобы не приходилось использовать scroll.\n",
    "    \n",
    "    \n",
    "А еще  если сомневаешься, как отформатировать правильно - всегда можно найти какой-нибудь оналйн-форматтер, например этот\n",
    "    \n",
    "  https://extendsclass.com/python-formatter.html\n",
    "    \n",
    "    \n",
    "В качестве дополнительного развития могу порекомендоваь книгу \"PYTHON  чистый код для продолжающих\", Эл Свейгарт    \n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "train_features = cv.fit_transform(train_features)\n",
    "test_features = cv.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7636424274650186\n",
      "{'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "model_lr = LogisticRegression(random_state=12345)\n",
    "lr_grid = GridSearchCV(model_lr,  param_grid=grid, scoring='f1')\n",
    "\n",
    "lr_grid.fit(train_features, train_target)\n",
    "\n",
    "best_score = lr_grid.best_score_\n",
    "best_params = lr_grid.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    " Совет: линейные модели очень хорошо работают с признаками, полученными из текстов. С помощью TF-IDF мы получили очень длинные разряженные вектора. И действительно, они очень длинные (длина около 140 000), при этом очень мало значений отличаются от нуля. Так вот, линейные модели гораздо лучше деревьев справляются с такими признаками. Но есть один секрет. Нужно  немного ослабить регуляризацию у логистической регрессии, и сделать это можно подобрав гиперпараметр С (чем он больше тем слабее регуляризация). Оптимальное значение стоит поискать в диапазоне 5-15. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "Не стоит раньше времени подглядывать в тестовую выборку. Вначале обучим все модели и выберем лучшую по оценкам на крос-валидации и только потом протестируем лучшую модель.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Тоже сделаю через гридсерч, мне нравится как он работает, и только потом тогда подсмотрим в тестовую выборку\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>v2</b> 👍 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность получилась хорошая, 0.76. Можно попробовать сделать ее лучше с помощью catboost'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3424968\ttotal: 1.03s\tremaining: 1m 41s\n",
      "25:\tlearn: 0.1546922\ttotal: 29.2s\tremaining: 1m 22s\n",
      "50:\tlearn: 0.1378414\ttotal: 54.6s\tremaining: 52.5s\n",
      "75:\tlearn: 0.1288637\ttotal: 1m 19s\tremaining: 25.2s\n",
      "99:\tlearn: 0.1217898\ttotal: 1m 42s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3351465\ttotal: 1.37s\tremaining: 2m 15s\n",
      "25:\tlearn: 0.1550014\ttotal: 29.4s\tremaining: 1m 23s\n",
      "50:\tlearn: 0.1369883\ttotal: 54.2s\tremaining: 52s\n",
      "75:\tlearn: 0.1275838\ttotal: 1m 17s\tremaining: 24.5s\n",
      "99:\tlearn: 0.1221900\ttotal: 1m 39s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3362582\ttotal: 983ms\tremaining: 1m 37s\n",
      "25:\tlearn: 0.1550819\ttotal: 26.3s\tremaining: 1m 14s\n",
      "50:\tlearn: 0.1364546\ttotal: 50.7s\tremaining: 48.8s\n",
      "75:\tlearn: 0.1292381\ttotal: 1m 15s\tremaining: 23.7s\n",
      "99:\tlearn: 0.1218034\ttotal: 1m 38s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3437178\ttotal: 1.36s\tremaining: 2m 14s\n",
      "25:\tlearn: 0.1557519\ttotal: 28.1s\tremaining: 1m 19s\n",
      "50:\tlearn: 0.1381969\ttotal: 53.6s\tremaining: 51.5s\n",
      "75:\tlearn: 0.1287879\ttotal: 1m 19s\tremaining: 25s\n",
      "99:\tlearn: 0.1221196\ttotal: 1m 42s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3528350\ttotal: 1.15s\tremaining: 1m 54s\n",
      "25:\tlearn: 0.1556996\ttotal: 27.3s\tremaining: 1m 17s\n",
      "50:\tlearn: 0.1379114\ttotal: 53.4s\tremaining: 51.3s\n",
      "75:\tlearn: 0.1287822\ttotal: 1m 17s\tremaining: 24.6s\n",
      "99:\tlearn: 0.1215889\ttotal: 1m 40s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3372473\ttotal: 19.1s\tremaining: 31m 27s\n",
      "25:\tlearn: 0.1345640\ttotal: 7m 32s\tremaining: 21m 28s\n",
      "50:\tlearn: 0.1148773\ttotal: 14m 23s\tremaining: 13m 49s\n",
      "75:\tlearn: 0.1040439\ttotal: 21m 15s\tremaining: 6m 42s\n",
      "99:\tlearn: 0.0989210\ttotal: 27m 53s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3351437\ttotal: 16.2s\tremaining: 26m 46s\n",
      "25:\tlearn: 0.1362034\ttotal: 6m 50s\tremaining: 19m 29s\n",
      "50:\tlearn: 0.1160602\ttotal: 14m 17s\tremaining: 13m 43s\n",
      "75:\tlearn: 0.1051134\ttotal: 21m 3s\tremaining: 6m 39s\n",
      "99:\tlearn: 0.1005573\ttotal: 27m 30s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3362622\ttotal: 16.7s\tremaining: 27m 37s\n",
      "25:\tlearn: 0.1354912\ttotal: 7m 23s\tremaining: 21m 3s\n",
      "50:\tlearn: 0.1147490\ttotal: 14m 43s\tremaining: 14m 8s\n",
      "75:\tlearn: 0.1045198\ttotal: 21m 59s\tremaining: 6m 56s\n",
      "99:\tlearn: 0.0985732\ttotal: 28m 33s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3436952\ttotal: 16.6s\tremaining: 27m 26s\n",
      "25:\tlearn: 0.1376985\ttotal: 7m 30s\tremaining: 21m 22s\n",
      "50:\tlearn: 0.1149043\ttotal: 14m 33s\tremaining: 13m 58s\n",
      "75:\tlearn: 0.1036358\ttotal: 21m 36s\tremaining: 6m 49s\n",
      "99:\tlearn: 0.0982118\ttotal: 28m 21s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3454831\ttotal: 16.5s\tremaining: 27m 12s\n",
      "25:\tlearn: 0.1372609\ttotal: 7m 14s\tremaining: 20m 35s\n",
      "50:\tlearn: 0.1166305\ttotal: 14m 19s\tremaining: 13m 45s\n",
      "75:\tlearn: 0.1051886\ttotal: 21m 12s\tremaining: 6m 41s\n",
      "99:\tlearn: 0.0990892\ttotal: 27m 52s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3374430\ttotal: 20.1s\tremaining: 33m 12s\n",
      "25:\tlearn: 0.1360433\ttotal: 9m 36s\tremaining: 27m 19s\n",
      "50:\tlearn: 0.1162944\ttotal: 18m 52s\tremaining: 18m 7s\n",
      "75:\tlearn: 0.1061869\ttotal: 27m 53s\tremaining: 8m 48s\n",
      "99:\tlearn: 0.1008229\ttotal: 36m 39s\tremaining: 0us\n",
      "0.7434671943681336\n",
      "{'depth': 12}\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'depth': [6,12]\n",
    "}\n",
    "model_cat = CatBoostClassifier(random_state=12345, verbose = 25, iterations = 100)\n",
    "model_cat = GridSearchCV(model_cat,  param_grid=grid,  scoring='f1')\n",
    "model_cat.fit(train_features, train_target)\n",
    "best_score = model_cat.best_score_ \n",
    "best_params = model_cat.best_params_\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность получилась равно 0.74, хороший результат, но недостаточный, посмотрим на результаты тестовой выборки для линейной регрессии, так как она выдает результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "Что-то здесь совсем запутано. Похоже на неудачный копипаст из предыдущего проекта. \n",
    "\n",
    " - зачем TimeSeriesSplit?\n",
    " - мы решаем задачу классификации, почему CatBoostRegressor   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Я просто был очень горд собой когда написал это первый раз и теперь это везде сую :) Я только после отправки понял что я написал catboostregressor вместо classifier, и точно также с тайм сериес\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>v2</b> Сейчас все ОК</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "И вот сейчас,когда ты исследовал две (или больше) моделей нужно выбрать одну лучшую и провести её тестирование \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>v2</b> 👍 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7594971303634873\n"
     ]
    }
   ],
   "source": [
    "predictions_test = lr_grid.best_estimator_.predict(test_features)\n",
    "print(f1_score(test_target, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность получилась выше 0.75, отличный результат!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам было сделано следующее:\n",
    "\n",
    "1. Импортированы и обработаны данные\n",
    "2. Данные лемматизированы и очищены\n",
    "3. Обучена и проверена модель обычной логистической регрессии, результат которой равен 0.76, результат неплохой\n",
    "4. Обучена модель градиентного бустинга, результат неудовлетворительный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель линейной регрессии оказалось лучшей и равна 0.76 по результат ф1 тестирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://s3.amazonaws.com/pix.iemoji.com/images/emoji/apple/ios-12/256/waving-hand.png\" align=left width=44, heigth=44>\n",
    "<div class=\"alert alert-info\">\n",
    "<b> Заключительный комментарий</b>\n",
    "Давай подведем итоги. В целом с проектом ты справляешься - текст предобработан, извлечены признаки и обучены классификаторы. Достигнуто требуемое значение метрики f1.\n",
    "    \n",
    "Но кое с чем нужно еще поработать. \n",
    "    \n",
    " - Пожалуста доработай раздел с лемматизацией. Сейчас она выполняется некорректно.\n",
    " - Нельзя раньше времени подглядыать в тестовую выборку.\n",
    " - Пожалуйста исправь ошибки в ячейке с кэтбустом.   \n",
    "\n",
    "\n",
    "     \n",
    "Жду твоих исправлений :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://s3.amazonaws.com/pix.iemoji.com/images/emoji/apple/ios-12/256/waving-hand.png\" align=left width=44, heigth=44>\n",
    "<div class=\"alert alert-info\">\n",
    "<b> рекомендации по доп. материалам</b>\n",
    "Если решишь погрузиться в область работы с текстами, очень советую несколько продвинутых бесплатных курсов.\n",
    "    \n",
    "   - Отличный бесплатный курс от Школы глубокого обучения МФТИ (https://stepik.org/org/dlschool), старт курса каждые пол года. Два семестра, один по основам и компьютерному зрению, второй по обработке естественного языка. Проходить нужно именно в таком порядке,т.к. почти весь современный NLP построен на нейронках.\n",
    "    \n",
    "   - \"Нейронные сети и компьютерное зрение\" от Samsung Research Russia (https://stepik.org/course/50352/syllabus). Есть также продолжение по NLP.  \n",
    "   - Трек NLP от сообщества ODS https://ods.ai/tracks/nlp-course-autumn-22\n",
    "    \n",
    "    \n",
    "А если на тебя произвели впечатление возможности ChatGPT и хочешь попробовать использовать возможности больших языковых моделей для решения своих задач, могу порекомендовать следующие курсы (но к сожалению все на английском).\n",
    "    \n",
    "  - https://www.coursera.org/learn/generative-ai-with-llms  (можно прослужать бесплатно)\n",
    "  - Короткие курсы на сайте https://www.deeplearning.ai/short-courses/  Самый свежак - как писать промпты, как использовать LLM для создания собственных приложений (например как создать бота на основе ChatGPT, который будет отвечать на вопросы по внутренней документации компании).  \n",
    "  - https://www.promptingguide.ai/introduction/settings\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Спасибо, но мне почему то очень тяжко дается работа с текстами, не знаю с чем это связано, оно мне совсем не нравится, остальное вот интересно, а тут почему то не очень.\n",
    "Возможно я просто это плохо понял и не до конца разобрался, очень тяжелый топик.\n",
    "Теория в этой части тоже почему то описана очень плохо :(\n",
    "Но вам спасибо большое за доп материалы\n",
    "Очень много времени ушло на переработку, спасибо еще раз за содействие\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://s3.amazonaws.com/pix.iemoji.com/images/emoji/apple/ios-12/256/waving-hand.png\" align=left width=44, heigth=44>\n",
    "<div class=\"alert alert-info\">\n",
    "<b> Заключительный комментарий v2</b>\n",
    "\n",
    "Я тебя понял. Да, тексты вначале кажутся сложноватыми, слишком много новых слов \"леммаизация\", \"токнизация\", мого деталей, новых библиотек...\n",
    "    \n",
    "Но на мой взгляд это сейчас самая интересная и бурно развивающаяся тема в машинном обучении, и революция LLM совершается на наших глазах ))\n",
    "    \n",
    "Проект принят. Поздравляю и желаю дальнейших успехов!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1751,
    "start_time": "2023-08-08T10:23:48.382Z"
   },
   {
    "duration": 3546,
    "start_time": "2023-08-08T10:23:50.135Z"
   },
   {
    "duration": 40,
    "start_time": "2023-08-08T10:24:04.334Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-08T10:24:22.956Z"
   },
   {
    "duration": 863,
    "start_time": "2023-08-08T10:24:54.510Z"
   },
   {
    "duration": 34,
    "start_time": "2023-08-08T10:24:55.375Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-08T10:24:57.046Z"
   },
   {
    "duration": 65,
    "start_time": "2023-08-09T08:35:29.049Z"
   },
   {
    "duration": 1916,
    "start_time": "2023-08-09T08:35:33.184Z"
   },
   {
    "duration": 2415,
    "start_time": "2023-08-09T08:35:35.102Z"
   },
   {
    "duration": 34,
    "start_time": "2023-08-09T08:35:37.519Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-09T08:35:37.555Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-09T08:35:39.729Z"
   },
   {
    "duration": 1468,
    "start_time": "2023-08-09T08:47:22.817Z"
   },
   {
    "duration": 3397,
    "start_time": "2023-08-09T09:08:47.968Z"
   },
   {
    "duration": 177,
    "start_time": "2023-08-09T09:12:31.366Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-09T09:12:45.552Z"
   },
   {
    "duration": 2571,
    "start_time": "2023-08-09T09:12:45.564Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-09T09:12:48.137Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-09T09:12:48.179Z"
   },
   {
    "duration": 30,
    "start_time": "2023-08-09T09:12:48.201Z"
   },
   {
    "duration": 34,
    "start_time": "2023-08-09T09:12:48.233Z"
   },
   {
    "duration": 658,
    "start_time": "2023-08-09T09:12:52.808Z"
   },
   {
    "duration": 726,
    "start_time": "2023-08-09T09:13:04.105Z"
   },
   {
    "duration": 1408,
    "start_time": "2023-08-09T09:13:56.713Z"
   },
   {
    "duration": 1468,
    "start_time": "2023-08-09T09:14:08.179Z"
   },
   {
    "duration": 25,
    "start_time": "2023-08-09T09:16:04.350Z"
   },
   {
    "duration": 102047,
    "start_time": "2023-08-09T09:16:17.091Z"
   },
   {
    "duration": 3309,
    "start_time": "2023-08-09T09:18:33.884Z"
   },
   {
    "duration": 901,
    "start_time": "2023-08-09T09:18:37.196Z"
   },
   {
    "duration": 32,
    "start_time": "2023-08-09T09:18:38.099Z"
   },
   {
    "duration": 67,
    "start_time": "2023-08-09T09:18:38.132Z"
   },
   {
    "duration": 43,
    "start_time": "2023-08-09T09:18:38.201Z"
   },
   {
    "duration": 41,
    "start_time": "2023-08-09T09:18:38.245Z"
   },
   {
    "duration": 21369,
    "start_time": "2023-08-09T09:18:41.324Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-09T09:19:17.422Z"
   },
   {
    "duration": 4905,
    "start_time": "2023-08-09T20:22:32.765Z"
   },
   {
    "duration": 2398,
    "start_time": "2023-08-09T20:22:37.672Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-09T20:22:40.071Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-09T20:22:40.109Z"
   },
   {
    "duration": 32,
    "start_time": "2023-08-09T20:22:40.126Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-09T20:22:40.160Z"
   },
   {
    "duration": 2008,
    "start_time": "2023-08-09T20:22:40.185Z"
   },
   {
    "duration": 40,
    "start_time": "2023-08-09T20:28:06.636Z"
   },
   {
    "duration": 265,
    "start_time": "2023-08-09T20:29:16.738Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-09T20:29:22.156Z"
   },
   {
    "duration": 1015403,
    "start_time": "2023-08-09T20:29:26.904Z"
   },
   {
    "duration": 61,
    "start_time": "2023-08-09T20:46:22.315Z"
   },
   {
    "duration": 1525,
    "start_time": "2023-08-09T20:49:39.932Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-09T20:49:48.299Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-09T20:53:49.031Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-09T20:54:02.122Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-09T20:54:05.287Z"
   },
   {
    "duration": 33,
    "start_time": "2023-08-09T20:54:08.508Z"
   },
   {
    "duration": 22,
    "start_time": "2023-08-09T21:01:43.637Z"
   },
   {
    "duration": 4061,
    "start_time": "2023-08-09T21:01:44.540Z"
   },
   {
    "duration": 33,
    "start_time": "2023-08-09T21:32:48.676Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-09T21:44:34.345Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-09T21:44:48.106Z"
   },
   {
    "duration": 42900,
    "start_time": "2023-08-09T21:44:52.018Z"
   },
   {
    "duration": 43586,
    "start_time": "2023-08-09T21:46:11.323Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-09T21:49:54.947Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-09T21:50:01.719Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-09T21:50:04.126Z"
   },
   {
    "duration": 3320,
    "start_time": "2023-08-09T21:50:07.240Z"
   },
   {
    "duration": 44972,
    "start_time": "2023-08-09T21:50:13.114Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-09T21:54:35.877Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-09T21:58:28.972Z"
   },
   {
    "duration": 3412664,
    "start_time": "2023-08-09T22:00:49.309Z"
   },
   {
    "duration": 89,
    "start_time": "2023-08-10T22:25:55.272Z"
   },
   {
    "duration": 3647,
    "start_time": "2023-08-11T14:52:30.094Z"
   },
   {
    "duration": 4774,
    "start_time": "2023-08-11T15:11:38.330Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-11T15:22:18.288Z"
   },
   {
    "duration": 4043,
    "start_time": "2023-08-11T15:22:18.298Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-11T15:22:22.356Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-11T15:22:22.397Z"
   },
   {
    "duration": 49,
    "start_time": "2023-08-11T15:22:22.435Z"
   },
   {
    "duration": 59,
    "start_time": "2023-08-11T15:22:22.486Z"
   },
   {
    "duration": 1049475,
    "start_time": "2023-08-11T15:22:29.374Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-11T15:39:58.851Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-11T15:40:49.735Z"
   },
   {
    "duration": 40,
    "start_time": "2023-08-11T15:41:39.270Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-11T15:48:32.988Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-11T16:03:54.455Z"
   },
   {
    "duration": 906,
    "start_time": "2023-08-11T16:03:54.466Z"
   },
   {
    "duration": 45,
    "start_time": "2023-08-11T16:03:55.374Z"
   },
   {
    "duration": 29,
    "start_time": "2023-08-11T16:03:55.429Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-11T16:03:55.460Z"
   },
   {
    "duration": 68,
    "start_time": "2023-08-11T16:03:55.500Z"
   },
   {
    "duration": 1041249,
    "start_time": "2023-08-11T16:03:55.571Z"
   },
   {
    "duration": 26,
    "start_time": "2023-08-11T16:21:16.822Z"
   },
   {
    "duration": 104,
    "start_time": "2023-08-11T16:21:16.850Z"
   },
   {
    "duration": 877183,
    "start_time": "2023-08-11T16:21:16.957Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-11T16:35:54.142Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-11T16:59:06.554Z"
   },
   {
    "duration": 9661,
    "start_time": "2023-08-11T16:59:40.179Z"
   },
   {
    "duration": 869225,
    "start_time": "2023-08-11T16:59:54.974Z"
   },
   {
    "duration": 18,
    "start_time": "2023-08-11T17:14:24.202Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-11T17:35:29.088Z"
   },
   {
    "duration": 1042662,
    "start_time": "2023-08-11T17:35:45.541Z"
   },
   {
    "duration": 22,
    "start_time": "2023-08-11T17:58:36.858Z"
   },
   {
    "duration": 9499,
    "start_time": "2023-08-11T17:59:24.336Z"
   },
   {
    "duration": 22,
    "start_time": "2023-08-11T17:59:48.346Z"
   },
   {
    "duration": 1100,
    "start_time": "2023-08-11T17:59:48.372Z"
   },
   {
    "duration": 75,
    "start_time": "2023-08-11T17:59:49.478Z"
   },
   {
    "duration": 26,
    "start_time": "2023-08-11T17:59:49.559Z"
   },
   {
    "duration": 149,
    "start_time": "2023-08-11T17:59:49.588Z"
   },
   {
    "duration": 116,
    "start_time": "2023-08-11T17:59:49.742Z"
   },
   {
    "duration": 1148608,
    "start_time": "2023-08-11T17:59:49.865Z"
   },
   {
    "duration": 116,
    "start_time": "2023-08-11T18:18:58.475Z"
   },
   {
    "duration": 55,
    "start_time": "2023-08-11T18:18:58.593Z"
   },
   {
    "duration": 794226,
    "start_time": "2023-08-11T18:18:58.651Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-11T18:32:12.879Z"
   },
   {
    "duration": 43,
    "start_time": "2023-08-11T18:45:14.278Z"
   },
   {
    "duration": 4314,
    "start_time": "2023-08-11T18:45:16.834Z"
   },
   {
    "duration": 6480,
    "start_time": "2023-08-11T18:45:56.463Z"
   },
   {
    "duration": 906,
    "start_time": "2023-08-11T18:46:02.946Z"
   },
   {
    "duration": 38,
    "start_time": "2023-08-11T18:46:03.853Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-11T18:46:03.893Z"
   },
   {
    "duration": 31,
    "start_time": "2023-08-11T18:46:03.924Z"
   },
   {
    "duration": 60,
    "start_time": "2023-08-11T18:46:03.957Z"
   },
   {
    "duration": 1056930,
    "start_time": "2023-08-11T18:46:04.022Z"
   },
   {
    "duration": 927085,
    "start_time": "2023-08-11T19:03:40.954Z"
   },
   {
    "duration": 25,
    "start_time": "2023-08-11T19:19:08.041Z"
   },
   {
    "duration": 94,
    "start_time": "2023-08-11T19:19:08.071Z"
   },
   {
    "duration": 4726,
    "start_time": "2023-08-11T19:19:08.166Z"
   },
   {
    "duration": 489,
    "start_time": "2023-08-11T19:19:12.894Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-11T19:19:13.385Z"
   },
   {
    "duration": 129,
    "start_time": "2023-08-11T19:54:45.903Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-11T19:55:01.140Z"
   },
   {
    "duration": 470777,
    "start_time": "2023-08-11T20:04:09.222Z"
   },
   {
    "duration": 6244,
    "start_time": "2023-08-11T21:03:55.487Z"
   },
   {
    "duration": 981,
    "start_time": "2023-08-11T21:04:01.735Z"
   },
   {
    "duration": 44,
    "start_time": "2023-08-11T21:04:02.726Z"
   },
   {
    "duration": 28,
    "start_time": "2023-08-11T21:04:02.771Z"
   },
   {
    "duration": 44,
    "start_time": "2023-08-11T21:04:02.801Z"
   },
   {
    "duration": 47,
    "start_time": "2023-08-11T21:04:02.847Z"
   },
   {
    "duration": 1096920,
    "start_time": "2023-08-11T21:04:02.896Z"
   },
   {
    "duration": 864673,
    "start_time": "2023-08-11T21:22:19.818Z"
   },
   {
    "duration": 37,
    "start_time": "2023-08-11T21:36:44.493Z"
   },
   {
    "duration": 51,
    "start_time": "2023-08-11T21:36:44.532Z"
   },
   {
    "duration": 5363,
    "start_time": "2023-08-11T21:36:44.585Z"
   },
   {
    "duration": 490164,
    "start_time": "2023-08-11T21:36:49.951Z"
   },
   {
    "duration": 538558,
    "start_time": "2023-08-11T21:45:00.117Z"
   },
   {
    "duration": 7425,
    "start_time": "2023-08-12T10:15:43.410Z"
   },
   {
    "duration": 3333,
    "start_time": "2023-08-12T10:15:50.843Z"
   },
   {
    "duration": 72,
    "start_time": "2023-08-12T10:15:54.178Z"
   },
   {
    "duration": 99,
    "start_time": "2023-08-12T10:15:54.256Z"
   },
   {
    "duration": 62,
    "start_time": "2023-08-12T10:15:54.357Z"
   },
   {
    "duration": 67,
    "start_time": "2023-08-12T10:15:54.421Z"
   },
   {
    "duration": 1114154,
    "start_time": "2023-08-12T10:15:54.490Z"
   },
   {
    "duration": 6975,
    "start_time": "2023-08-12T10:50:37.459Z"
   },
   {
    "duration": 5848,
    "start_time": "2023-08-12T10:52:07.432Z"
   },
   {
    "duration": 937,
    "start_time": "2023-08-12T10:52:13.283Z"
   },
   {
    "duration": 48,
    "start_time": "2023-08-12T10:52:14.226Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-12T10:52:14.276Z"
   },
   {
    "duration": 40,
    "start_time": "2023-08-12T10:52:14.296Z"
   },
   {
    "duration": 60,
    "start_time": "2023-08-12T10:52:14.338Z"
   },
   {
    "duration": 1071750,
    "start_time": "2023-08-12T10:52:14.401Z"
   },
   {
    "duration": 837557,
    "start_time": "2023-08-12T11:10:06.154Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-12T11:24:03.718Z"
   },
   {
    "duration": 95,
    "start_time": "2023-08-12T11:24:03.739Z"
   },
   {
    "duration": 5627,
    "start_time": "2023-08-12T11:24:03.836Z"
   },
   {
    "duration": 665096,
    "start_time": "2023-08-12T11:34:28.321Z"
   },
   {
    "duration": 11413456,
    "start_time": "2023-08-12T11:45:33.422Z"
   },
   {
    "duration": 92,
    "start_time": "2023-08-12T14:55:46.880Z"
   },
   {
    "duration": 360,
    "start_time": "2023-08-12T15:37:42.798Z"
   },
   {
    "duration": 24,
    "start_time": "2023-08-12T15:43:34.735Z"
   },
   {
    "duration": 29,
    "start_time": "2023-08-12T15:44:04.682Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-12T15:44:11.813Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
